{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5u_aruynnBDo"
   },
   "source": [
    "##### Copyright 2020 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKqvIgn4nFP7"
   },
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeQBWIOUgZSH"
   },
   "source": [
    "## Step 1: Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "4K3bU0aSMEwK",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Joseph\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Joseph\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Joseph\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Joseph\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Joseph\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful. Loading models...\n",
      "torch.abs ['input']\n",
      "torch.add ['input', 'other']\n",
      "torch.argmax ['input', 'dim']\n",
      "torch.argmin ['input', 'dim']\n",
      "torch.argsort ['input', 'dim']\n",
      "torch.argsort ['input']\n",
      "torch.broadcast_to ['input', 'shape']\n",
      "torch.Tensor.type ['dtype']\n",
      "torch.clamp ['input', 'min', 'max']\n",
      "torch.cat ['tensors', 'dim']\n",
      "torch.tensor ['data']\n",
      "torch.div ['input', 'other']\n",
      "torch.eq ['input', 'other']\n",
      "torch.exp ['input']\n",
      "torch.unsqueeze ['input', 'dim']\n",
      "torch.eye ['n']\n",
      "torch.eye ['n', 'm']\n",
      "torch.eye ['n', 'dtype']\n",
      "torch.gather ['input', 'dim', 'index']\n",
      "torch.gt ['input', 'other']\n",
      "torch.ge ['input', 'other']\n",
      "torch.bincount ['input']\n",
      "torch.ceil ['input']\n",
      "torch.count_nonzero ['input']\n",
      "torch.count_nonzero ['input', 'dim']\n",
      "torch.cumsum ['input', 'dim']\n",
      "torch.floor ['input']\n",
      "torch.log ['input']\n",
      "torch.neg ['input']\n",
      "torch.reciprocal ['input']\n",
      "torch.topk ['input', 'k']\n",
      "torch.matmul ['input', 'other']\n",
      "torch.maximum ['input', 'other']\n",
      "torch.minimum ['input', 'other']\n",
      "torch.mul ['input', 'other']\n",
      "torch.ne ['input', 'other']\n",
      "torch.nn.functional.one_hot ['tensor', 'num_classes']\n",
      "torch.ones ['size']\n",
      "torch.ones_like ['input']\n",
      "torch.nn.functional.pad ['input', 'pad']\n",
      "torch.nn.functional.pad ['input', 'pad', 'value']\n",
      "torch.nn.functional.pad ['input', 'pad']\n",
      "torch.nn.functional.pad ['input', 'pad']\n",
      "torch.range ['end']\n",
      "torch.range ['start', 'end', 'step']\n",
      "torch.any ['input', 'dim']\n",
      "torch.max ['input']\n",
      "torch.max ['input', 'dim']\n",
      "torch.mean ['input']\n",
      "torch.mean ['input', 'dim']\n",
      "torch.min ['input']\n",
      "torch.min ['input', 'dim']\n",
      "torch.prod ['input', 'dim']\n",
      "torch.sum ['input']\n",
      "torch.sum ['input', 'dim']\n",
      "torch.reshape ['input', 'shape']\n",
      "torch.flip ['input', 'dims']\n",
      "torch.roll ['input', 'shifts', 'dims']\n",
      "torch.round ['input']\n",
      "torch.searchsorted ['sorted_sequence', 'values']\n",
      "torch.searchsorted ['sorted_sequence', 'values']\n",
      "torch.sign ['input']\n",
      "torch.sort ['input', 'dim']\n",
      "torch.sort ['input', 'dim']\n",
      "torch.sqrt ['input']\n",
      "torch.square ['input']\n",
      "torch.squeeze ['input']\n",
      "torch.squeeze ['input', 'dim']\n",
      "torch.stack ['tensors', 'dim']\n",
      "torch.sub ['input', 'other']\n",
      "torch.tensordot ['a', 'b', 'dims']\n",
      "torch.tile ['input', 'reps']\n",
      "torch.transpose ['input']\n",
      "torch.unbind ['input', 'dim']\n",
      "torch.where ['condition']\n",
      "torch.where ['condition', 'x', 'y']\n",
      "torch.zeros ['shape']\n",
      "torch.zeros_like ['input']\n",
      "Could not load the tensor features model. If you see this message, please raise a GitHub issue (https://github.com/google-research/tensorflow-coder/issues) describing what happened.\n",
      "Done. TF-Coder is now ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to install and import TF-Coder.\n",
    "\n",
    "# Import TensorFlow and NumPy in case the user wants to create the example\n",
    "# programmatically.\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# !pip install tensorflow-coder\n",
    "from tf_coder.value_search import colab_interface\n",
    "from tf_coder.value_search import value_search_settings as settings_module\n",
    "\n",
    "from tf_coder_colab_logging import colab_logging\n",
    "\n",
    "\n",
    "print('Imports successful. Loading models...')\n",
    "colab_interface.warm_up()\n",
    "print('Done. TF-Coder is now ready to use!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_EbjwYGiU1Y"
   },
   "source": [
    "## Step 2: Describe the problem with an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdTDDuFMiXlp"
   },
   "source": [
    "Provide an **input-output example**:\n",
    "\n",
    "* `inputs` is a dictionary containing one or more input tensors with variable names.\n",
    "* `output` is the corresponding output tensor.\n",
    "\n",
    "Tensors can be provided as lists (possibly multidimensional) or `tf.Tensor` objects.\n",
    "\n",
    "You may also specify relevant **scalar constants**. TF-Coder also uses heuristics to guess a few useful constants.\n",
    "\n",
    "Finally, it often helps to provide an **English description** of the desired tensor manipulation. This description can help the tool decide which TensorFlow operations to prioritize.\n",
    "\n",
    "_Note: Please do not include confidential or personal information._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lWNAIUNgg3RJ"
   },
   "outputs": [],
   "source": [
    "# Edit this cell! Follow the format of the example below.\n",
    "\n",
    "# A dict mapping input variable names to input tensors.\n",
    "inputs = {\n",
    "    'rows': [10, 20, 30],\n",
    "    'cols': [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "# The corresponding output tensor.\n",
    "output = [[11, 12, 13, 14],\n",
    "          [21, 22, 23, 24],\n",
    "          [31, 32, 33, 34]]\n",
    "\n",
    "# A list of relevant scalar constants, if any.\n",
    "constants = []\n",
    "\n",
    "# An English description of the tensor manipulation.\n",
    "description = 'add two vectors with broadcasting to get a matrix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZK8-vAhiz6q"
   },
   "source": [
    "## Step 3: Run the TF-Coder tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cn8Ofoo6i1W0",
    "outputId": "f87d2359-84f4-4691-d272-96e9ca50737d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.abs ['input']\n",
      "torch.add ['input', 'other']\n",
      "torch.argmax ['input', 'dim']\n",
      "torch.argmin ['input', 'dim']\n",
      "torch.argsort ['input', 'dim']\n",
      "torch.argsort ['input']\n",
      "torch.broadcast_to ['input', 'shape']\n",
      "torch.Tensor.type ['dtype']\n",
      "torch.clamp ['input', 'min', 'max']\n",
      "torch.cat ['tensors', 'dim']\n",
      "torch.tensor ['data']\n",
      "torch.div ['input', 'other']\n",
      "torch.eq ['input', 'other']\n",
      "torch.exp ['input']\n",
      "torch.unsqueeze ['input', 'dim']\n",
      "torch.eye ['n']\n",
      "torch.eye ['n', 'm']\n",
      "torch.eye ['n', 'dtype']\n",
      "torch.gather ['input', 'dim', 'index']\n",
      "torch.gt ['input', 'other']\n",
      "torch.ge ['input', 'other']\n",
      "torch.bincount ['input']\n",
      "torch.ceil ['input']\n",
      "torch.count_nonzero ['input']\n",
      "torch.count_nonzero ['input', 'dim']\n",
      "torch.cumsum ['input', 'dim']\n",
      "torch.floor ['input']\n",
      "torch.log ['input']\n",
      "torch.neg ['input']\n",
      "torch.reciprocal ['input']\n",
      "torch.topk ['input', 'k']\n",
      "torch.matmul ['input', 'other']\n",
      "torch.maximum ['input', 'other']\n",
      "torch.minimum ['input', 'other']\n",
      "torch.mul ['input', 'other']\n",
      "torch.ne ['input', 'other']\n",
      "torch.nn.functional.one_hot ['tensor', 'num_classes']\n",
      "torch.ones ['size']\n",
      "torch.ones_like ['input']\n",
      "torch.nn.functional.pad ['input', 'pad']\n",
      "torch.nn.functional.pad ['input', 'pad', 'value']\n",
      "torch.nn.functional.pad ['input', 'pad']\n",
      "torch.nn.functional.pad ['input', 'pad']\n",
      "torch.range ['end']\n",
      "torch.range ['start', 'end', 'step']\n",
      "torch.any ['input', 'dim']\n",
      "torch.max ['input']\n",
      "torch.max ['input', 'dim']\n",
      "torch.mean ['input']\n",
      "torch.mean ['input', 'dim']\n",
      "torch.min ['input']\n",
      "torch.min ['input', 'dim']\n",
      "torch.prod ['input', 'dim']\n",
      "torch.sum ['input']\n",
      "torch.sum ['input', 'dim']\n",
      "torch.reshape ['input', 'shape']\n",
      "torch.flip ['input', 'dims']\n",
      "torch.roll ['input', 'shifts', 'dims']\n",
      "torch.round ['input']\n",
      "torch.searchsorted ['sorted_sequence', 'values']\n",
      "torch.searchsorted ['sorted_sequence', 'values']\n",
      "torch.sign ['input']\n",
      "torch.sort ['input', 'dim']\n",
      "torch.sort ['input', 'dim']\n",
      "torch.sqrt ['input']\n",
      "torch.square ['input']\n",
      "torch.squeeze ['input']\n",
      "torch.squeeze ['input', 'dim']\n",
      "torch.stack ['tensors', 'dim']\n",
      "torch.sub ['input', 'other']\n",
      "torch.tensordot ['a', 'b', 'dims']\n",
      "torch.tile ['input', 'reps']\n",
      "torch.transpose ['input']\n",
      "torch.unbind ['input', 'dim']\n",
      "torch.where ['condition']\n",
      "torch.where ['condition', 'x', 'y']\n",
      "torch.zeros ['shape']\n",
      "torch.zeros_like ['input']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'torch.Size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bbb87a8e343a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Results will be printed to the cell's output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m results = colab_interface.run_value_search_from_colab(\n\u001b[1;32m---> 39\u001b[1;33m     inputs, output, constants, description, settings)\n\u001b[0m",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\colab_interface.py\u001b[0m in \u001b[0;36mrun_value_search_from_colab\u001b[1;34m(inputs, output, constants, description, settings)\u001b[0m\n\u001b[0;32m    113\u001b[0m       \u001b[0mdescription_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDESCRIPTION_HANDLER\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m       \u001b[0mtensor_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTENSOR_MODEL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m       tensor_config=TENSOR_CONFIG)\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\value_search.py\u001b[0m in \u001b[0;36mrun_value_search_from_example\u001b[1;34m(inputs, output, settings, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m       source=source)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mrun_value_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\value_search.py\u001b[0m in \u001b[0;36mrun_value_search\u001b[1;34m(benchmark, settings, description_handler, tensor_model, tensor_config)\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[0moperations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moperations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m       \u001b[0mstart_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m       settings=settings)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m   \u001b[0mtotal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\value_search.py\u001b[0m in \u001b[0;36m_find_solutions\u001b[1;34m(benchmark, operations, start_time, settings)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m   \u001b[1;31m# The output value to search for.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m   \u001b[0moutput_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutputValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m   \u001b[1;31m# A list of OrderedDicts mapping Value objects to themselves. The i-th\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\value.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;34m\"\"\"Initializes an OutputValue to contain `value`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_coder_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOutputValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreconstruct_expression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\value.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    167\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor is empty.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalue_search_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_tensor_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\value.py\u001b[0m in \u001b[0;36mnew_fn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcached_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcached_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcached_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\value_search\\value.py\u001b[0m in \u001b[0;36mnum_elements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_coder_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_tensor_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_coder_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_tensor_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\BreadTeleportationTechnology\\2021spring\\704 PL\\PyTorch-Coder\\tf_coder\\tf_coder_utils.py\u001b[0m in \u001b[0;36mnum_tensor_elements\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnum_tensor_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m   \u001b[1;34m\"\"\"Returns the number of elements in a tensor as an int (primitive).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'torch.Size'"
     ]
    }
   ],
   "source": [
    "# Run this cell to invoke TF-Coder on the problem from Step 2.\n",
    "\n",
    "# Adapted from https://stackoverflow.com/questions/33769041\n",
    "inputs = {\n",
    "    'first': [-1, 0, -3, 2, 1, 3, 5, -1, -9, 2, 10],\n",
    "    'second': [12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32],\n",
    "}\n",
    "output = [6, 8, 9, 4, 32]\n",
    "constants = [1]\n",
    "description = 'select the values in the second tensor where the first tensor is greater than 1'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# How long to search for a solution, in seconds.\n",
    "time_limit = 60  #@param {type: \"integer\"}\n",
    "\n",
    "# How many solutions to find before stopping. If more than 1, the entire search will slow down.\n",
    "number_of_solutions = 1  #@param{type: \"integer\"}\n",
    "\n",
    "# Whether solutions must use all inputs, at least one input, or no such requirement.\n",
    "solution_requirement = \"all inputs\" #@param [\"all inputs\", \"one input\", \"no restriction\"]\n",
    "\n",
    "settings = settings_module.from_dict({\n",
    "    'timeout': time_limit,\n",
    "    'only_minimal_solutions': False,\n",
    "    'max_solutions': number_of_solutions,\n",
    "    'require_all_inputs_used': solution_requirement == 'all inputs',\n",
    "    'require_one_input_used': solution_requirement == 'one input',\n",
    "})\n",
    "\n",
    "\n",
    "    \n",
    "# Results will be printed to the cell's output.\n",
    "results = colab_interface.run_value_search_from_colab(\n",
    "    inputs, output, constants, description, settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju9GylK-m-r6"
   },
   "source": [
    "# &nbsp;\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKWOuU6Ilr-3"
   },
   "source": [
    "## Usage Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTkbOQf5v23k"
   },
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqaFf533vxdJ"
   },
   "source": [
    "* If TF-Coder finds a solution, it is _guaranteed_ that the solution produces\n",
    "  the example output when run on the example inputs. However, it is _not\n",
    "  guaranteed_ that the solution generalizes in the way you intend! Please\n",
    "  carefully review solutions produced by TF-Coder before using them in your real\n",
    "  project.\n",
    "\n",
    "* TF-Coder will often produce a solution that uses hardcoded constants for\n",
    "  shapes or lengths, e.g., `tf.reshape(to_flatten, (6,))` in order to flatten an\n",
    "  input tensor with shape `(2, 3)`. You may need to manually change these\n",
    "  constants to improve the generality of the solution, e.g., replacing `6` with\n",
    "  `-1` in this case. Use the shape attribute to obtain dimension lengths of\n",
    "  input tensors, e.g., `to_flatten.shape[0]` would be `2`.\n",
    "\n",
    "* If you want to play with TensorFlow in Colab (e.g., to understand how a\n",
    "  TF-Coder solution works or to test your own solution):\n",
    "  * The TF-Coder Colab already imports TensorFlow 2 and Numpy, for your\n",
    "    convenience.\n",
    "  * Use `tf.constant` to create a tensor from the list format:\n",
    "    ```\n",
    "    >>> tf.constant([[13, 22], [17, 5]])\n",
    "    <tf.Tensor: id=1, shape=(2, 2), dtype=int32, numpy=\n",
    "    array([[13, 22],\n",
    "           [17,  5]], dtype=int32)>\n",
    "\n",
    "    >>> tf.constant(12.3)\n",
    "    <tf.Tensor: id=2, shape=(), dtype=float32, numpy=12.3>\n",
    "    ```\n",
    "  * A Colab notebook can only have one cell running at a time. If you want to\n",
    "    experiment with TensorFlow code while TF-Coder is running, consider doing so\n",
    "    in a separate Python shell.\n",
    "\n",
    "* TF-Coder's running time is exponential in the complexity of the solution.\n",
    "  _Simplifying the problem_, or _breaking it down into multiple steps_, can help\n",
    "  TF-Coder find solutions quickly. For instance, if you know that a reshape,\n",
    "  transpose, cast, or other similar operation should be applied to an input or\n",
    "  as the last operation to produce the output, consider applying that operation\n",
    "  manually to the input-output example, to help TF-Coder focus on the more\n",
    "  difficult parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7vV5e0Iv_rz"
   },
   "source": [
    "#### Input-Output Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB337V-cwDbQ"
   },
   "source": [
    "Creating a good input-output example is crucial for TF-Coder to find the\n",
    "solution you want. The example should be robust enough to rule out _false\n",
    "positive solutions_, which are TensorFlow expressions that work on the given\n",
    "example, but fail to generalize in the desired way.\n",
    "\n",
    "Here are some techniques that reduce the risk of false positives:\n",
    "\n",
    "* **Include more numbers** in the input and output tensors. TF-Coder will only\n",
    "  output a solution if it works on the provided example, so having many numbers\n",
    "  in the output tensor means it is less likely for incorrect solutions to\n",
    "  produce all of the correct numbers by chance.\n",
    "\n",
    "* **Use random-looking numbers** in the input tensors. For example,\n",
    "  `[18, 73, 34, 51]` would be a better input tensor than `[1, 2, 3, 4]`, since\n",
    "  the former is not all consecutive and not all increasing. This helps eliminate\n",
    "  patterns in the input tensors that false positive solutions can take advantage\n",
    "  of.\n",
    "\n",
    "* **Remove patterns from the output other than the intended one**. For example,\n",
    "  if the output tensor is a selection of numbers from input tensors, make sure\n",
    "  the selected numbers aren't all the maximum element along some axis, unless\n",
    "  that is the intended pattern.\n",
    "\n",
    "* **Include edge cases** where relevant. These could include negative numbers,\n",
    "  zero, or duplicate numbers, when applicable to the problem.\n",
    "\n",
    "* **Distinguish between indices and non-indices**. If you know a number should\n",
    "  not be used as an index, consider making it out of range of valid indices\n",
    "  (negative, too large, or even floating-point).\n",
    "\n",
    "* **Follow any constraints that exist in your real program**. For example, if an\n",
    "  input tensor only contains positive numbers, TF-Coder may produce a solution\n",
    "  that doesn't generalize to negative numbers. Whether this is acceptable\n",
    "  depends on whether that tensor could possibly contain negative numbers in your\n",
    "  real program. Of course, depending on the problem, a completely general\n",
    "  solution may be unnecessarily harder to find.\n",
    "\n",
    "In general, false positive solutions are more common if the output tensor\n",
    "contains a relatively low amount of information given the inputs. This may\n",
    "happen if the output is a scalar or boolean tensor, or if the output is\n",
    "constructed by selecting one or a few elements from an input. When possible, try\n",
    "to include many numbers in the output so that it contains enough information to\n",
    "unambiguously identify the intended transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8J9OmOq_wHFJ"
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfL1sYB5wJxC"
   },
   "source": [
    "* TF-Coder will print out the list of constants that it is using, including\n",
    "  constants chosen through heuristics. This list is ordered with highest-\n",
    "  priority constants at the beginning.\n",
    "* If the intended solution requires a constant that is not in TF-Coder's printed\n",
    "  list of constants, then TF-Coder will be _unable_ to find the intended\n",
    "  solution. So, it is important to provide any necessary constants.\n",
    "* If you explicitly provide constants, they will be used with the highest\n",
    "  priority. Thus, even if TF-Coder's heuristics choose your desired constant, it\n",
    "  may be better to provide the constant explicitly so that TF-Coder is more\n",
    "  confident about using your constant.\n",
    "* Providing extraneous constants will slow down the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hex6HpsLwNzI"
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GnVYA7_wL-R"
   },
   "source": [
    "* The description is optional. If provided, it is used to prioritize TensorFlow\n",
    "  operations that fit with the description.\n",
    "* If you know of a TensorFlow operation (e.g., `tf.reduce_max`) that is\n",
    "  relevant, include its name (e.g., \"tf.reduce_max\") anywhere in the\n",
    "  description. This will lead TF-Coder to prioritize that operation.\n",
    "* If possible, try to describe how the output should be computed, rather than\n",
    "  what the output conceptually represents.\n",
    "* A good description is less important than a good input-output example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sKleZJIwQkM"
   },
   "source": [
    "#### Other Details and Advanced Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuDoERN0lx4a"
   },
   "source": [
    "* When running TF-Coder, you can set the time limit, the number of solutions to\n",
    "  find, and whether solutions are required to use inputs.\n",
    "  * Time limit: This is the maximum amount of time, in seconds, that TF-Coder\n",
    "    will spend on the problem before giving up. Note that you can stop the tool\n",
    "    at any time by pressing the cell's stop button.\n",
    "  * Number of solutions: TF-Coder can continue searching for more solutions\n",
    "    after the first solution is found. This can help you examine different ways\n",
    "    of solving the problem. However, enabling multiple solutions will cause the\n",
    "    entire search to slow down, even for the first solution.\n",
    "  * Solution requirement: By default, solutions are required to use every input\n",
    "    tensor at least once. This constraint can be relaxed to allow solutions that\n",
    "    use only one input (if there are multiple inputs), or even solutions that\n",
    "    use no inputs at all.\n",
    "\n",
    "* By default, integer tensors have a DType of `tf.int32`, and float tensors have\n",
    "  a DType of `tf.float32`. To specify a different DType, provide a `tf.Tensor`\n",
    "  object instead of a list. For example:\n",
    "  * If an input is given as `[3, 1, 7, 4]`, then it will have a DType of\n",
    "    `tf.int32`.\n",
    "  * If an input is given as `tf.constant([3, 1, 7, 4], dtype=tf.int64)`, then it\n",
    "    will have a DType of `tf.int64`.\n",
    "\n",
    "* A primitive scalar input can be specified with a Python float or int, and a\n",
    "  scalar tensor can be specified with a `tf.Tensor`:\n",
    "  * If an input is given as `[123]`, then it will be a 1-dimensional tensor with\n",
    "    shape `(1,)`, equivalent to `tf.constant([123])`.\n",
    "  * If an input is given as `123`, then it will remain a Python primitive int,\n",
    "    not a `tf.Tensor`.\n",
    "  * If an input is given as `tf.constant(123)`, then it will be a 0-dimensional\n",
    "    scalar tensor with shape `()`.\n",
    "\n",
    "* Input and output tensors can have at most 4 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHYlFkj6l5af"
   },
   "source": [
    "## Example problems that TF-Coder can solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIwb8VOombkU"
   },
   "source": [
    "Here are several examples of real-life problems that TF-Coder can solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfGTQ7hF4VPV"
   },
   "outputs": [],
   "source": [
    "# Real task encountered by a Googler.\n",
    "inputs = {\n",
    "    'tensor': [[0, 1, 0, 0],\n",
    "               [0, 1, 1, 0],\n",
    "               [1, 1, 1, 1]],\n",
    "}\n",
    "output = [[0.0, 1.0, 0.0, 0.0],\n",
    "          [0.0, 0.5, 0.5, 0.0],\n",
    "          [0.25, 0.25, 0.25, 0.25]]\n",
    "constants = []\n",
    "description = 'normalize the rows of a tensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wzohJ299ObT"
   },
   "outputs": [],
   "source": [
    "# Real task encountered by a Googler.\n",
    "inputs = {\n",
    "    'elements': [0, 0, 0, 1, 3, 3],\n",
    "}\n",
    "output = [[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]]\n",
    "constants = []\n",
    "description = 'pair each element with a counter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DvZW75z4ZwN"
   },
   "outputs": [],
   "source": [
    "# Real task encountered by a Googler.\n",
    "inputs = {\n",
    "    'sparse': tf.SparseTensor(\n",
    "        indices=[[0, 0, 0], [0, 1, 1], [1, 1, 1], [1, 1, 2]],\n",
    "        values=[1., 1., 1., 1.],\n",
    "        dense_shape=[2, 2, 800]),\n",
    "}\n",
    "output = tf.SparseTensor(\n",
    "    indices=[[0, 0, 0], [0, 1, 1]],\n",
    "    values=[1., 1.],\n",
    "    dense_shape=[1, 2, 800])\n",
    "constants = []\n",
    "description = 'slice index 0 of the first dimension of a SparseTensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rv8jFiQvQYEC"
   },
   "outputs": [],
   "source": [
    "# Real task encountered by a Googler.\n",
    "inputs = {\n",
    "    'lengths': [3, 4, 2, 1],\n",
    "}\n",
    "output = [[1, 1, 1, 0, 0],\n",
    "          [1, 1, 1, 1, 0],\n",
    "          [1, 1, 0, 0, 0],\n",
    "          [1, 0, 0, 0, 0]]\n",
    "constants = [5]\n",
    "description = 'create a mask for sequences of the given lengths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pL50uFHLyu8l"
   },
   "outputs": [],
   "source": [
    "# Real task encountered by a Googler.\n",
    "inputs = {\n",
    "    'segments': [ 1,  1,  1,  0,  0,  2],\n",
    "    'data':     [10, 20, 30, 14, 15, 26],\n",
    "}\n",
    "output = [14, 15, 10, 20, 30, 26]\n",
    "constants = []\n",
    "description = 'sort the segments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCvkqaXs4fyU"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://stackoverflow.com/questions/53054668\n",
    "inputs = {\n",
    "    'values': [37, 42, 42, 37, 28, 15, 42, 15],\n",
    "}\n",
    "output = [0, 1, 1, 0, 2, 3, 1, 3]\n",
    "constants = []\n",
    "description = 'group items by value and get the group indices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4hI5vMLYQNj"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://stackoverflow.com/questions/47816231\n",
    "inputs = {\n",
    "    'vector': [3, 5, 0, 2, 3, 3, 0],\n",
    "}\n",
    "output = [[1., 0., 0., 0., 1., 1., 0.],\n",
    "          [0., 1., 0., 0., 0., 0., 0.],\n",
    "          [0., 0., 1., 0., 0., 0., 1.],\n",
    "          [0., 0., 0., 1., 0., 0., 0.],\n",
    "          [1., 0., 0., 0., 1., 1., 0.],\n",
    "          [1., 0., 0., 0., 1., 1., 0.],\n",
    "          [0., 0., 1., 0., 0., 0., 1.]]\n",
    "constants = []\n",
    "description = 'binary tensor from vector indicating if elements are equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbbocD0o0PYC"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://stackoverflow.com/questions/44834739\n",
    "inputs = {\n",
    "    'scores': [[0.7, 0.2, 0.1],\n",
    "               [0.4, 0.5, 0.1],\n",
    "               [0.4, 0.4, 0.2],\n",
    "               [0.3, 0.4, 0.3],\n",
    "               [0.0, 0.0, 1.0]],\n",
    "}\n",
    "output = [[1, 0, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 0, 1]]\n",
    "constants = []\n",
    "description = 'compute argmax in each tensor and set it to 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUUUBi7HI3Hr"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://stackoverflow.com/questions/33769041\n",
    "inputs = {\n",
    "    'first': [-1, 0, -3, 2, 1, 3, 5, -1, -9, 2, 10],\n",
    "    'second': [12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32],\n",
    "}\n",
    "output = [6, 8, 9, 4, 32]\n",
    "constants = [1]\n",
    "description = 'select the values in the second tensor where the first tensor is greater than 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6uRr4x9WHRC"
   },
   "source": [
    "## Supported Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvHDbukUWNKn",
    "outputId": "80d91e78-31a0-45d2-d4e4-692a4064e3e6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to print all supported operations.\n",
    "colab_interface.print_supported_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "looking_for = 'collect_tensor_data'\n",
    "\n",
    "# looks for above var in each file\n",
    "# I know this code is ugly lol\n",
    "for root, dirs, files in os.walk('tf_coder'):\n",
    "    for dire in dirs:\n",
    "        try:\n",
    "            for file in os.listdir(os.path.join('tf_coder', dire)):\n",
    "                try:\n",
    "                    with open(os.path.join('tf_coder', dire, file)) as f:\n",
    "                        txt = f.read()\n",
    "                        \n",
    "                        if looking_for in txt:\n",
    "                            print(os.path.join(dire, file))\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "for file in os.listdir(os.path.join('tf_coder')):\n",
    "    try:\n",
    "        with open(os.path.join('tf_coder', file)) as f:\n",
    "            txt = f.read()\n",
    "            if looking_for in txt:\n",
    "                print(os.path.join(file))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sparse_coo_tensor(size=(2, 3)).layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.bincount.__doc__.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5u_aruynnBDo",
    "EKWOuU6Ilr-3",
    "pHYlFkj6l5af",
    "Q6uRr4x9WHRC",
    "NYWv_mSbmfOO"
   ],
   "name": "TF-Coder Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
